{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos y Depuraci√≥n\n",
    "# Recaudo de Rentas Cedidas - Series de Tiempo 2026\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Objetivo\n",
    "\n",
    "Este cuaderno implementa el **diagn√≥stico completo y depuraci√≥n estructural** de los datos de recaudo para preparar el modelado predictivo con t√©cnicas de series de tiempo de √∫ltima generaci√≥n (2026).\n",
    "\n",
    "### Alcance del An√°lisis:\n",
    "1. **Exploraci√≥n inicial**: Estructura, dimensiones, tipos de datos\n",
    "2. **Diagn√≥stico de calidad**: Valores faltantes, duplicados, inconsistencias\n",
    "3. **Identificaci√≥n de anomal√≠as**: Outliers extremos, valores negativos, transacciones en escala cero\n",
    "4. **Depuraci√≥n estructural**: Limpieza, normalizaci√≥n, validaci√≥n de integridad\n",
    "5. **An√°lisis temporal**: Rangos, gaps, estacionalidad preliminar\n",
    "\n",
    "---\n",
    "\n",
    "**Autor**: Sistema de An√°lisis Predictivo  \n",
    "**Fecha**: Febrero 2026  \n",
    "**Versi√≥n**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuraci√≥n de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas cargadas exitosamente\")\n",
    "print(f\"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos desde Excel\n",
    "print(\"üìÅ Cargando datos de BaseRentasCedidas...\")\n",
    "df_raw = pd.read_excel('../BaseRentasCedidas (1).xlsx')\n",
    "\n",
    "print(f\"\\n‚úÖ Datos cargados exitosamente\")\n",
    "print(f\"üìä Dimensiones: {df_raw.shape[0]:,} filas √ó {df_raw.shape[1]} columnas\")\n",
    "print(f\"üíæ Memoria utilizada: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploraci√≥n Inicial de Estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n general del dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"INFORMACI√ìN GENERAL DEL DATASET\")\n",
    "print(\"=\" * 80)\n",
    "df_raw.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRIMERAS 10 FILAS\")\n",
    "print(\"=\" * 80)\n",
    "display(df_raw.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COLUMNAS DISPONIBLES\")\n",
    "print(\"=\" * 80)\n",
    "for i, col in enumerate(df_raw.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identificaci√≥n de Columnas Clave para Series de Tiempo\n",
    "\n",
    "Para el an√°lisis de series de tiempo, necesitamos identificar:\n",
    "- **Variable temporal**: Vigencia, Fecha, Periodo, etc.\n",
    "- **Variable objetivo (target)**: Valor de recaudo\n",
    "- **Variables auxiliares**: Tipo de renta, entidad, categor√≠a, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas con datos temporales y de recaudo\n",
    "columnas_temporales = [col for col in df_raw.columns if any(x in col.lower() for x in ['vigencia', 'fecha', 'periodo', 'a√±o', 'mes'])]\n",
    "columnas_recaudo = [col for col in df_raw.columns if any(x in col.lower() for x in ['recaudo', 'valor', 'monto', 'ingreso'])]\n",
    "\n",
    "print(\"üóìÔ∏è  COLUMNAS TEMPORALES DETECTADAS:\")\n",
    "for col in columnas_temporales:\n",
    "    print(f\"  - {col}\")\n",
    "    if col in df_raw.columns:\n",
    "        print(f\"    Valores √∫nicos: {df_raw[col].nunique()}\")\n",
    "        print(f\"    Rango: {df_raw[col].min()} - {df_raw[col].max()}\")\n",
    "        print(f\"    Tipo: {df_raw[col].dtype}\\n\")\n",
    "\n",
    "print(\"\\nüí∞ COLUMNAS DE RECAUDO DETECTADAS:\")\n",
    "for col in columnas_recaudo:\n",
    "    print(f\"  - {col}\")\n",
    "    if col in df_raw.columns:\n",
    "        print(f\"    Valores no nulos: {df_raw[col].notna().sum():,} ({df_raw[col].notna().sum()/len(df_raw)*100:.1f}%)\")\n",
    "        print(f\"    Tipo: {df_raw[col].dtype}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Diagn√≥stico de Calidad de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de valores faltantes\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE VALORES FALTANTES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Columna': df_raw.columns,\n",
    "    'Valores_Faltantes': df_raw.isnull().sum(),\n",
    "    'Porcentaje': (df_raw.isnull().sum() / len(df_raw) * 100).round(2)\n",
    "}).sort_values('Porcentaje', ascending=False)\n",
    "\n",
    "missing_data = missing_data[missing_data['Valores_Faltantes'] > 0]\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    display(missing_data)\n",
    "    \n",
    "    # Visualizaci√≥n con missingno\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    msno.matrix(df_raw, ax=ax, sparkline=False)\n",
    "    plt.title('Matriz de Valores Faltantes', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"‚úÖ No se detectaron valores faltantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de duplicados\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE REGISTROS DUPLICADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "duplicados_totales = df_raw.duplicated().sum()\n",
    "print(f\"Duplicados completos: {duplicados_totales:,} ({duplicados_totales/len(df_raw)*100:.2f}%)\")\n",
    "\n",
    "if duplicados_totales > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Se detectaron registros duplicados que requieren revisi√≥n\")\n",
    "else:\n",
    "    print(\"‚úÖ No se detectaron duplicados completos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparaci√≥n de Datos para An√°lisis Temporal\n",
    "\n",
    "**NOTA IMPORTANTE**: Esta secci√≥n debe ajustarse seg√∫n las columnas reales del dataset.  \n",
    "Asumimos que existe una columna de `Vigencia` (a√±o) y una columna de valor de recaudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: AJUSTAR NOMBRES DE COLUMNAS SEG√öN DATASET REAL\n",
    "\n",
    "# Verificar si existen columnas clave\n",
    "if columnas_recaudo:\n",
    "    columna_recaudo = columnas_recaudo[0]  # Tomar la primera columna detectada\n",
    "    print(f\"‚úÖ Usando columna de recaudo: '{columna_recaudo}'\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se detect√≥ autom√°ticamente la columna de recaudo\")\n",
    "    print(\"Por favor, especificar manualmente en la siguiente celda\")\n",
    "    columna_recaudo = None\n",
    "\n",
    "if columnas_temporales:\n",
    "    columna_temporal = columnas_temporales[0]  # Tomar la primera columna detectada\n",
    "    print(f\"‚úÖ Usando columna temporal: '{columna_temporal}'\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se detect√≥ autom√°ticamente la columna temporal\")\n",
    "    print(\"Por favor, especificar manualmente en la siguiente celda\")\n",
    "    columna_temporal = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. An√°lisis Estad√≠stico de la Variable Objetivo (Recaudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if columna_recaudo and columna_recaudo in df_raw.columns:\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ESTAD√çSTICAS DESCRIPTIVAS: {columna_recaudo}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Filtrar valores num√©ricos v√°lidos\n",
    "    recaudo_valido = df_raw[columna_recaudo].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    if len(recaudo_valido) > 0:\n",
    "        estadisticas = recaudo_valido.describe()\n",
    "        print(estadisticas)\n",
    "        \n",
    "        # Estad√≠sticas adicionales\n",
    "        print(f\"\\nüìä ESTAD√çSTICAS ADICIONALES:\")\n",
    "        print(f\"  Mediana: ${recaudo_valido.median():,.2f}\")\n",
    "        print(f\"  Moda: ${recaudo_valido.mode()[0]:,.2f}\")\n",
    "        print(f\"  Coef. Variaci√≥n: {(recaudo_valido.std()/recaudo_valido.mean()*100):.2f}%\")\n",
    "        print(f\"  Asimetr√≠a (Skewness): {recaudo_valido.skew():.2f}\")\n",
    "        print(f\"  Curtosis: {recaudo_valido.kurtosis():.2f}\")\n",
    "        \n",
    "        # Identificar valores negativos\n",
    "        negativos = (recaudo_valido < 0).sum()\n",
    "        print(f\"\\n‚ö†Ô∏è  Valores negativos: {negativos:,} ({negativos/len(recaudo_valido)*100:.2f}%)\")\n",
    "        \n",
    "        # Identificar valores cercanos a cero\n",
    "        cerca_cero = ((recaudo_valido >= 0) & (recaudo_valido < 1000)).sum()\n",
    "        print(f\"üìâ Valores < $1,000: {cerca_cero:,} ({cerca_cero/len(recaudo_valido)*100:.2f}%)\")\n",
    "        \n",
    "        # Identificar outliers extremos (>800M seg√∫n plan)\n",
    "        outliers_extremos = (recaudo_valido > 8e8).sum()\n",
    "        print(f\"üö® Valores > $800M: {outliers_extremos:,} ({outliers_extremos/len(recaudo_valido)*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No hay valores v√°lidos para analizar\")\nelse:\n",
    "    print(\"‚ö†Ô∏è  Columna de recaudo no identificada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizaci√≥n de Distribuci√≥n de Recaudo"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if columna_recaudo and columna_recaudo in df_raw.columns:\n",
    "    recaudo_valido = df_raw[columna_recaudo].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    if len(recaudo_valido) > 0:\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=('Distribuci√≥n de Recaudo', 'Distribuci√≥n Log-Normal',\n",
    "                          'Box Plot', 'Densidad de Probabilidad'),\n",
    "            specs=[[{}, {}], [{}, {}]]\n",
    "        )\n",
    "        \n",
    "        # Histograma normal\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=recaudo_valido, name='Recaudo', nbinsx=50),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Histograma logar√≠tmico\n",
    "        recaudo_positivo = recaudo_valido[recaudo_valido > 0]\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=np.log10(recaudo_positivo), name='Log10(Recaudo)', nbinsx=50),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Box plot\n",
    "        fig.add_trace(\n",
    "            go.Box(y=recaudo_valido, name='Recaudo'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Densidad\n",
    "        from scipy.stats import gaussian_kde\n",
    "        if len(recaudo_positivo) > 1:\n",
    "            kde = gaussian_kde(recaudo_positivo.sample(min(10000, len(recaudo_positivo))))\n",
    "            x_range = np.linspace(recaudo_positivo.min(), recaudo_positivo.quantile(0.99), 100)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=x_range, y=kde(x_range), mode='lines', name='Densidad'),\n",
    "                row=2, col=2\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(height=800, showlegend=False, title_text=\"An√°lisis de Distribuci√≥n del Recaudo\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Detecci√≥n de Outliers con Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if columna_recaudo and columna_recaudo in df_raw.columns:\n",
    "    recaudo_valido = df_raw[columna_recaudo].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    if len(recaudo_valido) > 100:\n",
    "        print(\"üîç Detectando outliers con Isolation Forest...\")\n",
    "        \n",
    "        # Preparar datos\n",
    "        X = recaudo_valido.values.reshape(-1, 1)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "        outlier_labels = iso_forest.fit_predict(X)\n",
    "        \n",
    "        # Contar outliers\n",
    "        n_outliers = (outlier_labels == -1).sum()\n",
    "        print(f\"\\n‚ö†Ô∏è  Outliers detectados: {n_outliers:,} ({n_outliers/len(recaudo_valido)*100:.2f}%)\")\n",
    "        \n",
    "        # Valores extremos\n",
    "        outliers = recaudo_valido[outlier_labels == -1]\n",
    "        print(f\"\\nTop 10 outliers m√°s extremos:\")\n",
    "        print(outliers.nlargest(10).apply(lambda x: f\"${x:,.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. An√°lisis Temporal Preliminar\n",
    "\n",
    "Explorar c√≥mo se distribuye el recaudo a lo largo del tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este c√≥digo necesita ajustarse seg√∫n la estructura real de los datos\n",
    "# Por ahora, dejamos placeholder para completar una vez se explore el dataset\n",
    "\n",
    "print(\"‚è≥ Este an√°lisis se completar√° una vez se identifique la estructura temporal de los datos\")\n",
    "print(\"\\nPr√≥ximos pasos:\")\n",
    "print(\"1. Identificar columnas de fecha/periodo\")\n",
    "print(\"2. Agregar recaudo por periodo (mensual/trimestral/semestral)\")\n",
    "print(\"3. Analizar estacionalidad y tendencias\")\n",
    "print(\"4. Identificar gaps temporales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Resumen Ejecutivo de Diagn√≥stico\n",
    "\n",
    "### Hallazgos Cr√≠ticos Identificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMEN EJECUTIVO - DIAGN√ìSTICO DE DATOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä DIMENSIONES:\")\n",
    "print(f\"  Registros totales: {len(df_raw):,}\")\n",
    "print(f\"  Columnas: {df_raw.shape[1]}\")\n",
    "\n",
    "if columna_recaudo and columna_recaudo in df_raw.columns:\n",
    "    recaudo_valido = df_raw[columna_recaudo].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  PROBLEMAS DETECTADOS:\")\n",
    "    \n",
    "    # Valores negativos\n",
    "    negativos = (recaudo_valido < 0).sum()\n",
    "    if negativos > 0:\n",
    "        print(f\"  ‚ùå Valores negativos: {negativos:,} registros\")\n",
    "    \n",
    "    # Valores extremos\n",
    "    extremos = (recaudo_valido > 8e8).sum()\n",
    "    if extremos > 0:\n",
    "        print(f\"  üö® Outliers extremos (>$800M): {extremos:,} registros\")\n",
    "    \n",
    "    # Valores cercanos a cero\n",
    "    cerca_cero = ((recaudo_valido >= 0) & (recaudo_valido < 1000)).sum()\n",
    "    if cerca_cero > 10000:\n",
    "        print(f\"  üìâ Transacciones en escala cero (<$1,000): {cerca_cero:,} registros\")\n",
    "    \n",
    "    print(\"\\n‚úÖ ACCIONES REQUERIDAS:\")\n",
    "    print(\"  1. Auditar y corregir valores negativos\")\n",
    "    print(\"  2. Aplicar Winsorization/Capping a outliers extremos\")\n",
    "    print(\"  3. Filtrar o normalizar transacciones de bajo valor\")\n",
    "    print(\"  4. Validar integridad temporal\")\n",
    "    print(\"  5. Preparar agregaciones por horizonte temporal\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Exportar Datos para Siguiente Fase\n",
    "\n",
    "Guardar datos crudos para continuar con Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar copia de datos originales\n",
    "output_path = '../data/raw/datos_originales.parquet'\n",
    "df_raw.to_parquet(output_path, index=False)\n",
    "print(f\"‚úÖ Datos originales guardados en: {output_path}\")\n",
    "\n",
    "print(\"\\nüìã SIGUIENTE PASO:\")\n",
    "print(\"   Abrir cuaderno: 02_Feature_Engineering.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

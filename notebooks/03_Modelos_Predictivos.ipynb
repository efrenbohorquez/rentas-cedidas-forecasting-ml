{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Modelos Predictivos: Rentas Cedidas Municipales (Multi-Horizonte)\n",
                "# SARIMAX, Prophet, XGBoost y Deep Learning\n",
                "\n",
                "---\n",
                "\n",
                "## üìã Proyecto de Grado\n",
                "**T√≠tulo**: Predicci√≥n del Comportamiento de las Rentas Cedidas en el Financiamiento del R√©gimen Subsidiado de Salud a Nivel Municipal mediante Modelos de Machine Learning\n",
                "\n",
                "**Objetivo Mejorado**: Desarrollar modelos predictivos multi-horizonte (Mensual, Bimestral, Trimestral) para estimar ingresos por Rentas Cedidas, integrando mejores pr√°cticas de limpieza y feature engineering sugeridas por **NotebookLM**.\n",
                "\n",
                "### üß† NotebookLM Insights Integrados:\n",
                "1. **Interpolaci√≥n Temporal**: Manejo de valores faltantes preservando tendencias.\n",
                "2. **Codificaci√≥n C√≠clica**: Transformaci√≥n Seno/Coseno para variables temporales.\n",
                "3. **An√°lisis Multi-Escala**: Evaluaci√≥n en diferentes agregaciones temporales para robustez.\n",
                "\n",
                "---\n",
                "\n",
                "**Fecha**: Octubre-Diciembre 2025 (Periodo de Evaluaci√≥n)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuraci√≥n del Entorno"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importaciones generales\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "\n",
                "# Agregar directorio de scripts al path para importar m√≥dulos locales\n",
                "current_dir = Path(os.getcwd())\n",
                "scripts_dir = current_dir.parent / 'scripts'\n",
                "sys.path.append(str(scripts_dir))\n",
                "\n",
                "try:\n",
                "    import config\n",
                "    import utils\n",
                "    print(\"‚úÖ M√≥dulos locales (config, utils) importados correctamente.\")\n",
                "except ImportError as e:\n",
                "    print(f\"‚ö†Ô∏è Advertencia: No se pudieron importar m√≥dulos locales: {e}\")\n",
                "\n",
                "# Modelos Econom√©tricos\n",
                "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
                "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
                "\n",
                "# Modelos ML y Prophet\n",
                "from prophet import Prophet\n",
                "# from neuralprophet import NeuralProphet # No instalado en este entorno\n",
                "import xgboost as xgb\n",
                "\n",
                "# Deep Learning\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "# Optimizaci√≥n y Validaci√≥n\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "%matplotlib inline\n",
                "\n",
                "print(\"‚úÖ Entorno configurado.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Ingenier√≠a de Caracter√≠sticas Din√°mica (NotebookLM Insights)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üí° NotebookLM Insight: Feature Engineering para Series Temporales\n",
                "Seg√∫n el an√°lisis de **NotebookLM (Video 7)**, para modelos de Deep Learning y Machine Learning en series temporales es crucial:\n",
                "1. **Preservar la Ciclidad**: Usar transformaciones Seno/Coseno para meses y trimestres evitar que el modelo interprete \"Mes 12\" y \"Mes 1\" como distantes.\n",
                "2. **Ventanas de Tiempo (Lags)**: Incorporar rezagos (t-1, t-12) permite al modelo capturar autocorrelaci√≥n directa.\n",
                "3. **Diferenciaci√≥n**: Estabilizar la media eliminando tendencias lineales simples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def feature_engineering_dynamic(df_input, freq='M'):\n",
                "    \"\"\"\n",
                "    Genera features din√°micamente seg√∫n la frecuencia (Horizonte) solicitada.\n",
                "    \"\"\"\n",
                "    df = df_input.copy()\n",
                "    \n",
                "    # Asegurar datetime\n",
                "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
                "    \n",
                "    # Agregaci√≥n por el horizonte deseado (Suma de Recaudo)\n",
                "    df_agg = df.groupby(pd.Grouper(key='fecha', freq=freq))['recaudo'].sum().reset_index()\n",
                "    df_agg = df_agg.sort_values('fecha')\n",
                "    \n",
                "    # Generar variables de tiempo\n",
                "    df_agg['mes'] = df_agg['fecha'].dt.month\n",
                "    df_agg['trimestre'] = df_agg['fecha'].dt.quarter\n",
                "    \n",
                "    # --- NotebookLM Technique: Cyclical Encoding ---\n",
                "    df_agg['sin_mes'] = np.sin(2 * np.pi * df_agg['mes'] / 12)\n",
                "    df_agg['cos_mes'] = np.cos(2 * np.pi * df_agg['mes'] / 12)\n",
                "    \n",
                "    # --- NotebookLM Technique: Lags ---\n",
                "    # Ajustamos lags seg√∫n la frecuencia\n",
                "    lags = [1, 2, 3] # Lags inmediatos\n",
                "    if freq == 'M':\n",
                "        lags.append(12) # Estacionalidad anual para mensual\n",
                "    elif freq == 'Q':\n",
                "        lags.append(4) # Estacionalidad anual para trimestral\n",
                "        \n",
                "    for lag in lags:\n",
                "        df_agg[f'recaudo_lag{lag}'] = df_agg['recaudo'].shift(lag)\n",
                "        \n",
                "    # Diferenciaci√≥n\n",
                "    df_agg['recaudo_diff'] = df_agg['recaudo'].diff().fillna(0)\n",
                "    \n",
                "    # Eliminar NaNs generados por lags iniciales\n",
                "    df_final = df_agg.dropna()\n",
                "    \n",
                "    return df_final\n",
                "\n",
                "print(\"‚úÖ Funci√≥n de Feature Engineering Din√°mica definida.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Definici√≥n de Modelos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- SARIMAX ---\n",
                "def entrenar_sarimax(train_series, order=(1,1,1), seasonal_order=(1,1,1,12)):\n",
                "    try:\n",
                "        model = SARIMAX(train_series, order=order, seasonal_order=seasonal_order,\n",
                "                        enforce_stationarity=False, enforce_invertibility=False)\n",
                "        return model.fit(disp=False)\n",
                "    except: return None\n",
                "\n",
                "# --- Prophet ---\n",
                "def entrenar_prophet(train_df, features_exogenas):\n",
                "    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, seasonality_mode='multiplicative')\n",
                "    for reg in features_exogenas: model.add_regressor(reg)\n",
                "    return model\n",
                "\n",
                "# --- XGBoost ---\n",
                "def entrenar_xgboost(X_train, y_train):\n",
                "    model = xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=6)\n",
                "    return model\n",
                "\n",
                "# --- LSTM ---\n",
                "class LSTMNet(nn.Module):\n",
                "    def __init__(self, input_dim, hidden_dim=50, output_dim=1):\n",
                "        super(LSTMNet, self).__init__()\n",
                "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
                "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
                "    def forward(self, x):\n",
                "        out, _ = self.lstm(x)\n",
                "        return self.fc(out[:, -1, :])\n",
                "\n",
                "print(\"‚úÖ Modelos definidos.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Ejecuci√≥n Multi-Horizonte (Mensual, Bimestral, Trimestral)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cargar datos crudos depurados (Excel)\n",
                "print(f\"üìÇ Cargando datos depurados desde: {config.CLEANED_DATA_FILE}\")\n",
                "df_raw = utils.load_data(config.CLEANED_DATA_FILE)\n",
                "\n",
                "horizontes = {\n",
                "    'Mensual': 'M',\n",
                "    'Bimestral': '2ME', # Using 2ME (Month End) standard\n",
                "    'Trimestral': 'Q'\n",
                "}\n",
                "\n",
                "resultados_globales = []\n",
                "\n",
                "for nombre_horizonte, frecuencia in horizontes.items():\n",
                "    print(f\"\\n\" + \"=\"*60)\n",
                "    print(f\"üïê Procesando Horizonte: {nombre_horizonte.upper()} ({frecuencia})\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # 1. Feature Engineering espec√≠fico para la frecuencia\n",
                "    try:\n",
                "        df_h = feature_engineering_dynamic(df_raw, freq=frecuencia)\n",
                "    except Exception as e:\n",
                "        if frecuencia == '2ME': \n",
                "             print(\"‚ö†Ô∏è Fallback a freq='2M' param old pandas...\")\n",
                "             df_h = feature_engineering_dynamic(df_raw, freq='2M')\n",
                "        else: raise e\n",
                "\n",
                "    # 2. Split (Oct-Dec 2025 Test)\n",
                "    split_date = pd.Timestamp(config.TRAIN_CUTOFF_DATE)\n",
                "    train = df_h[df_h['fecha'] <= split_date]\n",
                "    test = df_h[df_h['fecha'] > split_date]\n",
                "    \n",
                "    print(f\"   üöÇ Train: {len(train)} registros | üß™ Test: {len(test)} registros\")\n",
                "    if test.empty: \n",
                "        print(\"   ‚ö†Ô∏è Skip: No hay datos para test.\")\n",
                "        continue\n",
                "\n",
                "    # 3. Entrenamiento y Predicci√≥n\n",
                "    # --- SARIMAX ---\n",
                "    try:\n",
                "        ts_train = train.set_index('fecha')['recaudo']\n",
                "        # Ajuste din√°mico de estacionalidad\n",
                "        seasonal_periods = {'M': 12, '2ME': 6, '2M': 6, 'Q': 4}\n",
                "        s = seasonal_periods.get(frecuencia, 12)\n",
                "        \n",
                "        model_s = entrenar_sarimax(ts_train, seasonal_order=(1,1,1,s))\n",
                "        \n",
                "        if model_s:\n",
                "            pred_s = model_s.forecast(steps=len(test))\n",
                "            mape_s = mean_absolute_percentage_error(test['recaudo'], pred_s)\n",
                "            print(f\"   üìä SARIMAX (s={s}) MAPE: {mape_s:.2%}\")\n",
                "            resultados_globales.append({'Horizonte': nombre_horizonte, 'Modelo': 'SARIMAX', 'MAPE': mape_s})\n",
                "        else:\n",
                "             print(\"   ‚ö†Ô∏è SARIMAX no convergi√≥.\")\n",
                "    except Exception as e: print(f\"   ‚ùå SARIMAX Error: {e}\")\n",
                "\n",
                "    # --- XGBoost ---\n",
                "    try:\n",
                "        features = [c for c in df_h.columns if c not in ['fecha', 'recaudo']]\n",
                "        X_train = train[features].select_dtypes(include=[np.number])\n",
                "        X_test = test[features].select_dtypes(include=[np.number])\n",
                "        \n",
                "        model_x = xgb.XGBRegressor()\n",
                "        model_x.fit(X_train, train['recaudo'])\n",
                "        pred_x = model_x.predict(X_test)\n",
                "        mape_x = mean_absolute_percentage_error(test['recaudo'], pred_x)\n",
                "        print(f\"   üå≥ XGBoost MAPE: {mape_x:.2%}\")\n",
                "        resultados_globales.append({'Horizonte': nombre_horizonte, 'Modelo': 'XGBoost', 'MAPE': mape_x})\n",
                "    except Exception as e: print(f\"   ‚ùå XGBoost Error: {e}\")\n",
                "\n",
                "print(\"\\n‚úÖ Ejecuci√≥n Multi-Horizonte Completada.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Resumen de Resultados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_res = pd.DataFrame(resultados_globales)\n",
                "if not df_res.empty:\n",
                "    print(df_res.sort_values(['Horizonte', 'MAPE']))\n",
                "    # Guardar reporte\n",
                "    # df_res.to_excel(\"reporte_multihorizonte.xlsx\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}